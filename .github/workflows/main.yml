name: CI/CD Pipeline
on:
  push:
    branches: [ main ]
jobs:
  continuous-integration:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
          architecture: x64
      - name: Setup Virtual env
        uses: actions/cache@v4
        id: cache-venv
        with:
          path: venv
          key: ${{ runner.os }}-venv-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-venv-
      - name: Activate and Install Dependencies into Virtual env
        run: |
          python -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
        if: steps.cache-venv.outputs.cache-hit != 'true'
      - name: Add pytest for testing only
        run: |
          source venv/bin/activate
          pip install pytest
      - name: Set up environment variables
        run: |
          echo "GROQ_API_KEY=${{ secrets.GROQ_API_KEY }}" >> $GITHUB_ENV
          echo "ONE_INCH_API_KEY=${{ secrets.ONE_INCH_API_KEY }}" >> $GITHUB_ENV
          echo "PINECONE_API_KEY=${{ secrets.PINECONE_API_KEY }}" >> $GITHUB_ENV
          echo "PINECONE_INDEX_NAME=${{ secrets.PINECONE_INDEX_NAME }}" >> $GITHUB_ENV
          echo "ALCHEMY_API_KEY=${{ secrets.ALCHEMY_API_KEY }}" >> $GITHUB_ENV
      - name: Build and Run Test
        run: |
          source venv/bin/activate
          python -m pytest -v test_api.py
        working-directory: ./
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          ONE_INCH_API_KEY: ${{ secrets.ONE_INCH_API_KEY }}
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
          PINECONE_INDEX_NAME: ${{ secrets.PINECONE_INDEX_NAME }}
          ALCHEMY_API_KEY: ${{ secrets.ALCHEMY_API_KEY }}
      - name: Package Application for Lambda
        run: |
          # Create deployment package directory
          mkdir -p deployment
          
          # Install dependencies into deployment directory
          pip install -r requirements.txt -t deployment/
          
          # Create a wrapper lambda_function.py that points to our handler
          echo 'import sys' > deployment/lambda_function.py
          echo 'sys.path.append("/var/task")' >> deployment/lambda_function.py
          echo 'from api.main import lambda_handler' >> deployment/lambda_function.py
          
          # Copy the api folder containing main.py
          cp -r api deployment/
          
          # Copy all Python modules from root
          cp *.py deployment/ || echo "Some Python files may not exist"
          
          # Create deployment package
          cd deployment
          zip -r9 ../lambda_function.zip .
          cd ..
          
          # Check zip size
          ls -lh lambda_function.zip
      - name: Upload Lambda Function Code to S3
        run: |
          aws s3 cp lambda_function.zip s3://crypto-swaptest/lambda_function.zip
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
      - name: Deploy Lambda Function
        run: |
          aws lambda update-function-code \
            --function-name serverless \
            --s3-bucket crypto-swaptest \
            --s3-key lambda_function.zip
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}